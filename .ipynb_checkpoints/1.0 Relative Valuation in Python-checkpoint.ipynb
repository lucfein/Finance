{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Valuation (Public Comparables) in Python\n",
    "\n",
    "Resources used:\n",
    "\n",
    "<ul>\n",
    "     <li><a href=https://www.youtube.com/watch?v=ng2o98k983k&ab_channel=CoreySchafer>Web Scraping with BS4</a></li>\n",
    "    <li><a href=https://www.youtube.com/watch?v=tb8gHvYlCFs&ab_channel=CoreySchafer>API Requests with Requests</a></li>\n",
    "    <li> Valuation (Rosenbaum)</li>\n",
    "    <li><a href=https://www.barrons.com/articles/the-best-way-to-value-aerospace-and-defense-1506089535> Barrons: Aerospace Valuation (Stallard)</a></li>\n",
    "    \n",
    "</ul>\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction/thesis\n",
    "\n",
    "<p><i>Disclaimer</i>: Unfortunately, exporting the Jupyter Notebook to HTML and then trying to style it has been a disaster. Needless to say, for future Python projects I will do up the Jupyter Markdown in HTML, then screenshot/snip the code windows and output as pictures, rather than export it directly with NBConvert. Due to technical difficulties in the CSS, this page does not have a mobile version as of yet. Why? The exported HTML Jupyter file has <i>21000</i> lines of code. 21000. It has internal CSS, JS all in one. It is impossible to style the notebook without messing up something. </p>\n",
    "                        \n",
    "As per the title, the objective of this project is to write a simple program that, given a certain company, comparables criteria, and several other inputs, returns us a nice football field diagram and range of implied share prices from the comps set.\n",
    "\n",
    "<b><i>In a nutshell</i></b>: <br>\n",
    "\n",
    "In a more Pythonic setting, there are several ways of retrieving the data:\n",
    "<ul>\n",
    "<li>Interfacing with an API of a financial database to retrieve the data (FinancialModelling Prep API) using Requests, which often returns a JSON object.\n",
    "<li>Using a package (Yfinance, yahoo_fin) that has already scraped the data for you.\n",
    "<li>Scraping from the web off a financial database website (FinViz or Yahoo Finance) using Requests and BeautifulSoup.\n",
    "    \n",
    "Once that is done, we need to do some data manipulation and arithmetic with Pandas and Numpy to derive the range of implied share price for each multiple, then plot a football field chart.\n",
    "</ul>\n",
    "\n",
    "<b><i>From Rosenbaum</i></b>: <br>\n",
    "<blockquote>“Comparable companies analysis (“comparable companies”, “trading comps”, or simply “comps”) is one of the primary methodologies used for valuing a given focus company, division, business, or collection of assets (“target”). It provides a market benchmark against which a banker can establish valuation for a private company or analyze the value of a public company at a given point in time. ”</blockquote>\n",
    "\n",
    "Comps is designed to reflect the “current valuation” based on prevailing market sentiment, as compared to the intrinsic value provided by a DCF.\n",
    "\n",
    "\n",
    "\n",
    "<b>Comps has 5 main steps:</b>\n",
    "\n",
    "<ul>\n",
    "<li>Select the universe of comparable companies\n",
    "<li>Locate necessary financial information\n",
    "<li>Spread key statistics, ratios and multiples\n",
    "<li>Benchmark the Comparable companies\n",
    "<li>Determine valuation\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.2 Setup\n",
    "\n",
    "* Unfortunately, we are limited by the range of companies covered by the particular API/Financial database tool that we use. As such, I’ll be using `FinViz` for the initial comps selection and `yahoo_fin` for the valuation, and FinViz limits itself to stocks on the AMEX, NASDAQ and NYSE. As per the time of writing, there are 7538 stocks on FinViz, so that should be sufficient, and this method does not work for any stock outside of these exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import yahoo_fin.stock_info as si\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import requests_html\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "ua = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\"}\n",
    "apikey = \"a433140b7a107f7c4d1abdf9f3816b8e\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Select initial comps set\n",
    "\n",
    "* We need to tell the computer to search in FinViz our target stock, then from the HTML table returned, scrape the Industry and Country. \n",
    "\n",
    "\n",
    "<b>Handling multiple pages</b>:\n",
    "\n",
    "* However, this does not handle multiple pages. My proposed idea is: create the extra r=1 argument in the `unscreenedSet` function, then scrape the total # of items, % to round things off, for loop and call recursively the function again.\n",
    "\n",
    "* r=x is the parameter for the ticker number for FinViz. So on page 2, it would be `r=21` or the 21st item, and page 3, `r=41`, so on and so forth.\n",
    "\n",
    "* It would look like `while r <= total no. of items: tickerList.extend(unscreenedSet(country,ind, r=21)), then r +=20.` Since each page has 20 items, it would go from `21 >> 41 >> 61 >> etc`, incrementing by 20 each time.\n",
    "\n",
    "\n",
    "* *Edit*: But for now, I'll just make it crawl 3 pages, which is 60 stocks. Should be enough. I used a lazy solution, a simple for loop. No need for recursion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return industry and country for a particular stock\n",
    "\n",
    "def getDetails(target):\n",
    "    #create the response object\n",
    "    response = requests.get(f\"https://finviz.com/screener.ashx?v=111&t={target}\", headers=ua)\n",
    "    #create the soup object\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "    #retrieve the specific values with a class identifier\n",
    "    vals = soup.find_all(class_=\"screener-body-table-nw\")\n",
    "    ind = vals[4].string\n",
    "    ind = ind.replace(\" \",\"\")\n",
    "    ind = ind.replace(\"&\",\"\")\n",
    "    country = vals[5].string\n",
    "    country = country.replace(\" \",\"\")\n",
    "    country = country.replace(\"&\",\"\")\n",
    "    \n",
    "    return country, ind\n",
    "  \n",
    "    \n",
    "#function to return the unscreened comps set by industry and country. However, this does not handle multiple pages!\n",
    "\n",
    "def unscreenedSet(target):\n",
    "    \n",
    "    r=1\n",
    "    \n",
    "    country = getDetails(target)[0]\n",
    "    ind = getDetails(target)[1]\n",
    "    tickerList = []\n",
    "    \n",
    "    for r in range(0,5):\n",
    "    #create the response object\n",
    "        response = requests.get(f\"https://finviz.com/screener.ashx?v=111&f=geo_{country},ind_{ind}&r={r}1\",\n",
    "                                headers=ua)\n",
    "        #create the soup object\n",
    "        soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "        vals = soup.find_all(class_=\"screener-link-primary\")\n",
    "\n",
    "        for i in range(len(vals)):\n",
    "            ticker = vals[i].string\n",
    "            tickerList.append(ticker)\n",
    "    \n",
    "    return set(tickerList)\n",
    "  \n",
    "    \n",
    "tickerList = unscreenedSet(\"BA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 List of initial comps\n",
    "\n",
    "* So, we want to do RV for Boeing (\"BA\"). We restrict the set to companies in the US and in the same industry, Aerospace & Defense. As we can see, the usual names like Raytheon, Lockheed Martin, Northrop Grumman, all these companies part of the military industrial complex, are in the list. There are 44 companies in the US and in this industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VEC', 'AIRI', 'CUB', 'RTX', 'WWD', 'SWBI', 'AAXN', 'DCO', 'NPK', 'HII', 'TXT', 'IVAC', 'SPCE', 'ISSC', 'BWXT', 'MOG-A', 'ATRO', 'BA', 'GD', 'HXL', 'NOC', 'VTSI', 'HEI', 'MRCY', 'LHX', 'POWW', 'AJRD', 'CVU', 'KAMN', 'TDG', 'CODA', 'ASTC', 'SPR', 'AVAV', 'RGR', 'SIF', 'PKE', 'HEI-A', 'VSEC', 'UAVS', 'LMT', 'TGI', 'KTOS', 'AIR'}\n"
     ]
    }
   ],
   "source": [
    "print(tickerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tickerList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Narrow down to actual comps set\n",
    "\n",
    "* So now we have a function that returns a list of tickers that are from the same country and industry as the target stock. Now we want to return <b>n-nearest neighbours (aka 10)</b> to form our final comps set. So instead of setting a range like\n",
    "`x < Revenue < y`,\n",
    "we will just take the nearest neighbours.\n",
    "\n",
    "* We will first need a function, which given a ticker list, finds their Revenue, EBITDA, and MarketCap, and appends it into a dataFrame. \n",
    "\n",
    "* I wanted to take MarketCap but the API was wonky and kept giving me errors. So I decided to not include it\n",
    "\n",
    "* then, based on the target metrics, we will find the absolute distance between the target metric and the rest of the metrics, sort, then take 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_float(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return x\n",
    "    if 'k' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('k', '')) * 1000\n",
    "        return 1000.0\n",
    "    if 'M' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('M', '')) * 1000000\n",
    "        return 1000000.0\n",
    "    if 'B' in x:\n",
    "        return float(x.replace('B', '')) * 1000000000\n",
    "    \n",
    "    if \"%\" in x:\n",
    "        return float(x.replace('%', ''))\n",
    "    return 0.0\n",
    "\n",
    "#function, given a ticker list, finds their Revenue, EBITDA, and MarketCap, and appends it into a dataFrame\n",
    "\n",
    "def createCompsTable(tickerList):\n",
    "    revenueList = []\n",
    "    ebitdaList = []\n",
    "\n",
    "    for ticker in tickerList:\n",
    "        revenue = si.get_income_statement(ticker).reset_index().iloc[15,1]\n",
    "        ebitda = si.get_stats(ticker).iloc[38,1]\n",
    "        revenueList.append(revenue)\n",
    "        ebitdaList.append(ebitda)\n",
    "       \n",
    "    ct = pd.DataFrame(zip(tickerList,revenueList,ebitdaList), columns = [\"ticker\",\"revenue\",\"ebitda\"])\n",
    "    ct.set_index(\"ticker\", inplace=True)\n",
    "    ct[\"ebitda\"]=ct[\"ebitda\"].apply(value_to_float)\n",
    "    \n",
    "    return ct \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = createCompsTable(tickerList)\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Top 10\n",
    "\n",
    "* Now here is the function that gives us 10 nearest neighbours to the target by revenue or EBITDA. By default, it takes revenue. But it can be customized with `screenCompsList(ct,target,\"ebitda\")`. We first subtract the target's metric off the rest of the column, do a sort by descending (target with 0 is first), and slice the **first 11**  (target + 10 comparable companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screenCompsList(ct, target, metric=\"revenue\"):\n",
    "    \n",
    "        ct[metric]= abs(ct[metric]-ct[metric][target])\n",
    "        ct.sort_values(metric, inplace=True)\n",
    "        final = list(ct.iloc[:11,].index)\n",
    "        \n",
    "        return final\n",
    "    \n",
    "    \n",
    "final = screenCompsList(ct,\"BA\")\n",
    "final2 = screenCompsList(ct,\"BA\",\"ebitda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Based on Revenue, the final comps set is {final}.\")\n",
    "print(f\"Based on EBITDA, the final comps set is {final2}\\n\")\n",
    "\n",
    "print(f\"The only two stocks in common between the two sets are  {list(pd.Series(final)[pd.Series(final).isin(final2)])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, we can see in terms of Revenue, Boeing's closest comparables are `Raytheon`, `Lockheed Martin`, `General Dynamics`, `Northtrop`, `L3Harris` tech etc.\n",
    "\n",
    "\n",
    "* Interestingly, based on EBITDA, the function yields a very different comps set! `Raytheon` and `Lockheed` nowhere to be found. Instead, we have `Virgin Galactic`. Why did Finviz consider `Virgin Galactic` under \"Aerospace & Defense\"? From Google, Virgin Galactic is a commercial spaceflight company. They do not sell defense solutions or arms. Also, given the difference in comps set, it seems that EBITDA has varied quite tremendously in the past year, explaining why the two sets are so different. From above, only `SPR` (Spirit Aerosystems)  is in both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Build comps table\n",
    "\n",
    "\n",
    "* However, we have this article from Barrons, featuring Rob Stallard from Vertical Research, saying P/FCF is the best multiple for Aerospace. Stallard was an MD at RBC covering the Aerospace industry in M&A.\n",
    "<a href=https://www.barrons.com/articles/the-best-way-to-value-aerospace-and-defense-1506089535>The Best Way to value Aerospace  and Defense: P/FCF</a>. Why P/FCF? Why FCF in particular? I have no idea. I know that certain multiples are used in certain industries, but is there a more statistical reason as to why, like being backed up by some data, rather than just 'accounting wisdom', so to speak. This is a project for another time. Would it be possible to \"prove\" the effectiveness of valuation multiples for different industries using data? Hypothetically, one would assume that metric has the most deviation.\n",
    "\n",
    "Now we have our final 10 set of comps for `Boeing` (`BA`). Now all the hard work is done, we just need to use an API, or use `yahoo_fin`'s various modules to get our data. Our comps metrics would be:\n",
    "\n",
    "(L = last = T = trailing, N = Next,  TM = 12 Months, EV = Enterprise Value, P/E = Price/Earnings, FCF = Free Cash Flow, OCF = Operating Cash Flow)\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li>EV/Revenue (TTM)</li> \n",
    "    <li><b>EV/Revenue</b> </li>\n",
    "    <li>EV/Revenue (NTM)</li>\n",
    "    <li>EV/EBITDA (TTM)</li>\n",
    "    <li><b>EV/EBITDA</b>  </li>\n",
    "    <li>EV/EBITDA (NTM)</li>\n",
    "    <li><b>P/E (forward)</b> </li>\n",
    "    <li>P/E (TTM)</li>\n",
    "    <li><b>P/FCF</b></li>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "Equation for FCF: <br>\n",
    "<center>$FCF = OCF - CapEx$</center>\n",
    "\n",
    "Equation for P/FCF: <br>\n",
    "<center><i>P/FCF = P (avg of past 2020 weekly prices)/ FCF (per share)</i></center>\n",
    "\n",
    "* However, I'd just use the bolded ones to save time. Will use `shares outstanding`, not `diluted shares outstanding` for simplicity, so no treasury stock method. \n",
    "\n",
    "* Same method as above, so create empty `list`, `for` loop, call, `append`, and `zip` together in a dataframe. As have scrubbed the set (albeit not manually) from 44 companies to 10, this should load quicker.\n",
    "\n",
    "* Since FCF requires OCF & Capex which requires two separate calls, the function will do the other  metrics first, create the df, then do P/FCF separately and join it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalCompsTable(final):\n",
    "    \n",
    "    #function part 1 (everything but p/fcf)\n",
    "    \n",
    "    mcL, evL, evrttmL, evrL, evettmL, eveL, pefL, pfcfL, sharesL= [],[],[],[],[],[],[],[],[]\n",
    "    metricsL = [mcL,evL,evrttmL,evrL,evettmL,eveL,pefL]\n",
    "\n",
    "    for ticker in final:\n",
    "\n",
    "        k = si.get_stats_valuation(ticker).set_index(\"Unnamed: 0\").iloc[[0,1,-2,-1,3],[0,-2]]\n",
    "        #mc, ev, ev/rev, ev/ebitda, p/e forward\n",
    "        mc, ev, evrttm, evr, evettm, eve, pef = k.iloc[0,0], k.iloc[1,0], k.iloc[2,1], k.iloc[2,0], k.iloc[3,1] ,k.iloc[3,0],  k.iloc[4,0]\n",
    "        metrics = [mc,ev,evrttm, evr,evettm, eve,pef]\n",
    "\n",
    "\n",
    "        for metric, metricL in zip(metrics,metricsL):\n",
    "            metricL.append(metric)\n",
    "\n",
    "    f = pd.DataFrame(zip(final, mcL,evL,evrttmL,evrL,evettmL,eveL,pefL),columns=\n",
    "         [\"ticker\",\"marketcap\",\"enterprisevalue\",\"ev/revenue ttm\",\"ev/revenue\",\"ev/ebitda ttm\",\"ev/ebitda\",\"p/e forward\"])\n",
    "\n",
    "    \n",
    "    #function part 2 (p/fcf). price is an average of past weeks starting from start of this year, 2020.\n",
    "    \n",
    "    for ticker in final:\n",
    "\n",
    "        avgp = si.get_data(ticker,start_date=\"2020-01-01\",interval=\"1wk\").close.mean()\n",
    "        fcf = si.get_cash_flow(ticker).loc[['totalCashFromOperatingActivities','capitalExpenditures']].reset_index().iloc[:,1].sum()\n",
    "        shares = value_to_float(si.get_stats(ticker).iloc[9,-1])\n",
    "        fcfps = fcf/shares\n",
    "        pfcf = avgp/fcfps\n",
    "        \n",
    "        pfcfL.append(pfcf)\n",
    "        sharesL.append(shares)\n",
    "        \n",
    "    f[\"p/fcf\"] = pfcfL\n",
    "    f[\"shares outstanding\"] = sharesL\n",
    "    \n",
    "    return f\n",
    "\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = finalCompsTable(final)\n",
    "f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, GD `General Dynamics`, has empty values due to missing data. We'll fill it in with data from <a href=https://www.macrotrends.net/stocks/charts/GD/general-dynamics/price-fcf>MacroTrends.Net</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f.iloc[3,-2] = 16.08  #fcf\n",
    "f.iloc[3,-1] = 286.97*1000**2 #shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Perform valuation\n",
    "\n",
    "* We first exclude the target, then get our quartiles <b>(max,75th,median,25th,min)</b>.\n",
    "\n",
    "* Once we get our quartiles, we multiply each multiple by the relevant target denominator to derive EV or P.\n",
    "* we'll recycle the code from past functions, like `getCompsTable`\n",
    "\n",
    "Retrieving TTM Revenue and TTM EBITDA and forward EPS from `yahoo_fin` is too much hassle, so I'm going to cheat and grab these values from the Yahoo Finance website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1 Getting the quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartilefunction(f):\n",
    "    quartiles = f.iloc[1:,[3,4,5,6,7,8]]\n",
    "    quartiles = quartiles.astype(float)\n",
    "    q = quartiles.describe().round(decimals=2).iloc[3:,:]\n",
    "    return q \n",
    "\n",
    "\n",
    "def denomfunction(target):\n",
    "    ttmrevenue = 60765000*1000\n",
    "    revenue = float(si.get_income_statement(target).reset_index().iloc[15,1])\n",
    "    ttmebitda = -4197000*1000\n",
    "    ebitda = value_to_float(si.get_stats(target).iloc[38,1])\n",
    "    shares = value_to_float(si.get_stats(\"BA\").iloc[9,-1])\n",
    "    fcf = fcf = si.get_cash_flow(target).loc[['totalCashFromOperatingActivities','capitalExpenditures']].reset_index().iloc[:,1].sum()\n",
    "    feps = -0.45\n",
    "    fcfps = fcf/shares\n",
    "    \n",
    "    #package into numpy array for later\n",
    "    g = [ttmrevenue,revenue, ttmebitda, ebitda, feps, fcfps]\n",
    "    vals = np.array(g)\n",
    "    \n",
    "    return vals\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = quartilefunction(f)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = denomfunction(\"BA\")\n",
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 Conversion to equity value\n",
    "* Unfortunately, out of all the metrics, only the first two were positive (TTM Revenue, Revenue). The rest (TTM EBITDA, EBITDA, Forward EPS, FCF/share) are all negative. This is probably because of COVID impacting the aerospace industry. \n",
    "\n",
    "* We can multiply `q` by `vals` to get our enterprise value and price, giving us `multiples`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterprise values \n",
    "\n",
    "multiples = q.mul(vals,axis=1)\n",
    "multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have to drop the last two columns, because they give a negative price due to negative forward EPS & FCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evDf = multiples.iloc[:,0:4]\n",
    "evDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.3 Finding implied share price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we just need to convert the implied Enterprise Value to the implied Equity Value, and divide by the number of shares outstanding to get our <b>implied share price.</b>  I like to think as Enterprise Value as the theoretical \"takeover cost\" a buyer must incur to takeover the firm. Using this logic, higher debt increases the TEV, because a buyer who buys the firm will takeover the debt and incur higher costs. Any spare cash the firm has is used to pay off debt, hence minus cash.\n",
    "\n",
    "<center>$TEV = Equity Value + TotalDebt - Cash$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = si.get_balance_sheet(\"BA\")\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return debt and cash:\n",
    "def debtandcash(target):\n",
    "    bs = si.get_balance_sheet(target)\n",
    "    debt = bs.iloc[:,0][\"shortLongTermDebt\"] + bs.iloc[:,0][\"longTermDebt\"]\n",
    "    cash = bs.iloc[:,0][\"cash\"]\n",
    "    print(f\"The target stock: '{target}' has ${debt} debt and ${cash} cash.\")\n",
    "    return debt,cash\n",
    "\n",
    "debt,cash = debtandcash(\"BA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqval = evDf.iloc[:,:4]\n",
    "shares = f.iloc[0,-1]\n",
    "\n",
    "def impliedSharePrice(eqval, debt, cash, shares):\n",
    "    #convert to equity value\n",
    "    eqval = eqval + cash - debt\n",
    "    #divide by outstanding shares\n",
    "    implied_share_price = eqval/shares\n",
    "    print(\"here are the implied share prices.\")\n",
    "    return implied_share_price\n",
    "\n",
    "implied_share_price = impliedSharePrice(eqval,debt,cash,shares)\n",
    "valuation = pd.concat([implied_share_price,multiples.iloc[:,4:]], axis=1)\n",
    "valuation.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.4 Football field diagram\n",
    "\n",
    "* From the valuation ranges, only the first two are usable due to having solely positive values. `ev/ebitda ttm`, `ev/ebitda`, `p/e forward` and `p/fcf` (Stallard's metric) are all negative due to <i>negative denominators</i> in the industry. \n",
    "\n",
    "* `pd.melt()`: when searching how to seaborn boxplot with multiple columns of a dataframe, for a single boxplot in SeaBorn this link: <a href=\"https://stackoverflow.com/questions/49554139/boxplot-of-multiple-columns-of-a-pandas-dataframe-on-the-same-figure-seaborn\">pd.melt</a> was suggested, which unrolls the df into a df of shape (n,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "iqr = valuation.iloc[[1,2,3],:]\n",
    "\n",
    "def footballfield(iqr, target):\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(15,9))\n",
    "    graph = pd.melt(iqr)\n",
    "    sns.boxplot(data=graph,x=\"value\",y=\"variable\", whis=0, fliersize=0,width=0.5)\n",
    "\n",
    "    #sharepriceline\n",
    "    currentprice = si.get_live_price(target).round(3)\n",
    "    plt.text(x=250,y=1,s=f\"Current Price: ${currentprice}\",fontsize= 15,bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    plt.axvline(currentprice, color='red', linestyle=\"--\")\n",
    "\n",
    "    ax.set_title(label =\"Football Field Diagram\", fontsize=18, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Share Price', fontsize=15)\n",
    "    ax.set_ylabel('Multiple', fontsize=15)\n",
    "    sns.set_context(\"talk\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footballfield(iqr,\"BA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Well, unfortunately, due to negative denominators the IQRs are all over the place. We'd drop all the negative values, leaving us with `ev/revenue` & `ev/revenue ttm`. The trailing 12 months implies a higher valuation range, because Covid was not as bad back then. I would have used forecasts for multiples, but unfortunately, accessing them is alot of hassle, it would require quite abit more code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footballfield(iqr.iloc[:,[0,1]],\"BA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on the only reasonble metric, `ev/revenue` with a median of 178.5, the target is overvalued by 21.65%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Conclusion\n",
    "\n",
    "* And that concludes the notebook! Obviously, this isn't a practical way of doing comparables, because Bloomberg Terminals and other Terminals have a built in comps screener for you, but this was just some exploration. \n",
    "\n",
    "\n",
    "* <b>Functions</b>: Due to using an in-built example of a target rather than just building functions and a meta-function to call of the functions at the end, the script is not entirely one giant function (input your target, assumptions, ranges and output a football field graph in one function), but it can be adapted, in case anyone ever needs to build comps fast next time.\n",
    "\n",
    "\n",
    "* <b>Technical valuation details</b>: I know there are technical details overlooked with regard to the valuation, like not including forward or projected multiples, not using diluted shares outstanding, not looking at calendarization to ensure the periods are standardized and nice, etc. I know there is also the issue of not using NTM or forward-looking multiples, because extracting them out of the API/data was too troublesome.\n",
    "\n",
    "\n",
    "* <b>Data</b>: There are several ways of accessing financial data with Python. One is to manually scrape it yourself going to places like `Finviz` or `Yahoo Finance` or any other database. Another is to make requests to APIs like `financialmodellingprep API` or similar stock market APIs. And another is to use packages like `yahoo_fin`, `yfinance`, etc that already do their own scraping from a database. But these all have limited data. For example, `finviz` only covers stocks listed in US exchanges. \n",
    "\n",
    "\n",
    "* <b>Valuation</b>: The problem with valuation is that it really is impossible to prove a link between any valuation method and the \"true\" stock price, because the price is fundamentally based on supply and demand, which is determined by people's perception of the stock and the market, and different entities will always have different perspectives. \n",
    "\n",
    "* <b>NBConvert Export to HTML</b>: Exporting to HTML using NBConvert was a disaster. LaTeX markdown not working, font sizes too small, CSS selectors not working. The Jupyter HTML output comes with internal CSS and finding the right selector is impossible. I can't figure out how to make the font-size of the code output and dataframe output larger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cash_flow(\"BA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.99px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
